{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b91bd2e",
   "metadata": {},
   "source": [
    "# CSV Embeddings with Pandas\n",
    "Create embeddings for tabular data (CSV files) and perform semantic search on the embeddings using ChromaDB."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5005af68",
   "metadata": {},
   "source": [
    "## 1. Install Required Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540f7e3b",
   "metadata": {},
   "source": [
    "## 2. Import Libraries & Load CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b6d6e49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1013 rows\n",
      "\n",
      "Columns: ['act', 'prompt', 'for_devs', 'type', 'contributor']\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>act</th>\n",
       "      <th>prompt</th>\n",
       "      <th>for_devs</th>\n",
       "      <th>type</th>\n",
       "      <th>contributor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ethereum Developer</td>\n",
       "      <td>Imagine you are an experienced Ethereum develo...</td>\n",
       "      <td>True</td>\n",
       "      <td>TEXT</td>\n",
       "      <td>ameya-2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linux Terminal</td>\n",
       "      <td>I want you to act as a linux terminal. I will ...</td>\n",
       "      <td>True</td>\n",
       "      <td>TEXT</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>English Translator and Improver</td>\n",
       "      <td>I want you to act as an English translator, sp...</td>\n",
       "      <td>False</td>\n",
       "      <td>TEXT</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Job Interviewer</td>\n",
       "      <td>I want you to act as an interviewer. I will be...</td>\n",
       "      <td>False</td>\n",
       "      <td>TEXT</td>\n",
       "      <td>f,iltekin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JavaScript Console</td>\n",
       "      <td>I want you to act as a javascript console. I w...</td>\n",
       "      <td>True</td>\n",
       "      <td>TEXT</td>\n",
       "      <td>omerimzali</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               act  \\\n",
       "0               Ethereum Developer   \n",
       "1                   Linux Terminal   \n",
       "2  English Translator and Improver   \n",
       "3                  Job Interviewer   \n",
       "4               JavaScript Console   \n",
       "\n",
       "                                              prompt  for_devs  type  \\\n",
       "0  Imagine you are an experienced Ethereum develo...      True  TEXT   \n",
       "1  I want you to act as a linux terminal. I will ...      True  TEXT   \n",
       "2  I want you to act as an English translator, sp...     False  TEXT   \n",
       "3  I want you to act as an interviewer. I will be...     False  TEXT   \n",
       "4  I want you to act as a javascript console. I w...      True  TEXT   \n",
       "\n",
       "  contributor  \n",
       "0  ameya-2003  \n",
       "1           f  \n",
       "2           f  \n",
       "3   f,iltekin  \n",
       "4  omerimzali  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from scipy.spatial import distance\n",
    "import chromadb\n",
    "\n",
    "# Load CSV file\n",
    "csv_file = \"/Users/kipronno/Mini Projects/prompts.csv\"\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "print(f\"Loaded {len(df)} rows\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11e0033",
   "metadata": {},
   "source": [
    "## 3. Load Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "380af49e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 103/103 [00:00<00:00, 1580.48it/s, Materializing param=pooler.dense.weight]                             \n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Load the SentenceTransformer model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec13f339",
   "metadata": {},
   "source": [
    "## 4. Generate Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "324c98eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:05<00:00,  5.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 1013 embeddings\n",
      "Each embedding dimension: (384,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Select the text column and convert to list\n",
    "descriptions = df['prompt'].tolist()\n",
    "\n",
    "# Generate embeddings\n",
    "embeddings = model.encode(descriptions, convert_to_numpy=True, show_progress_bar=True)\n",
    "\n",
    "print(f\"Generated {len(embeddings)} embeddings\")\n",
    "print(f\"Each embedding dimension: {embeddings[0].shape if len(embeddings) > 0 else 'N/A'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b6a4a2",
   "metadata": {},
   "source": [
    "## 5. Semantic Search Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4325d246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function defined!\n"
     ]
    }
   ],
   "source": [
    "def find_similar_items(query_text, embeddings, df, n_results=3):\n",
    "    # Encode query text\n",
    "    query_embedding = model.encode([query_text], convert_to_numpy=True)[0]\n",
    "    \n",
    "    # Calculate cosine distances\n",
    "    distances = [distance.cosine(query_embedding, emb) for emb in embeddings]\n",
    "    \n",
    "    # Find top n results\n",
    "    top_indices = np.argsort(distances)[:n_results]\n",
    "    \n",
    "    return df.iloc[top_indices]\n",
    "\n",
    "print(\"Function defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c17047",
   "metadata": {},
   "source": [
    "## 6. Test Semantic Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "040308e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: 'Similar prompts'\n",
      "\n",
      "==================================================\n",
      "Top 3 similar items:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>act</th>\n",
       "      <th>prompt</th>\n",
       "      <th>for_devs</th>\n",
       "      <th>type</th>\n",
       "      <th>contributor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>Prompt Enhancer</td>\n",
       "      <td>Act as a Prompt Enhancer AI that takes user-in...</td>\n",
       "      <td>True</td>\n",
       "      <td>TEXT</td>\n",
       "      <td>iuzn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>Reverse Prompt Engineer</td>\n",
       "      <td>I want you to act as a Reverse Prompt Engineer...</td>\n",
       "      <td>True</td>\n",
       "      <td>TEXT</td>\n",
       "      <td>jcordon5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>Senior Prompt Engineer Role Guide</td>\n",
       "      <td>Senior Prompt Engineer,\"Imagine you are a worl...</td>\n",
       "      <td>False</td>\n",
       "      <td>TEXT</td>\n",
       "      <td>iamcanturk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   act  \\\n",
       "165                    Prompt Enhancer   \n",
       "214            Reverse Prompt Engineer   \n",
       "363  Senior Prompt Engineer Role Guide   \n",
       "\n",
       "                                                prompt  for_devs  type  \\\n",
       "165  Act as a Prompt Enhancer AI that takes user-in...      True  TEXT   \n",
       "214  I want you to act as a Reverse Prompt Engineer...      True  TEXT   \n",
       "363  Senior Prompt Engineer,\"Imagine you are a worl...     False  TEXT   \n",
       "\n",
       "    contributor  \n",
       "165        iuzn  \n",
       "214    jcordon5  \n",
       "363  iamcanturk  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test semantic search\n",
    "query1 = \"Similar prompts\"\n",
    "\n",
    "print(f\"Query: '{query1}'\")\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "results1 = find_similar_items(query1, embeddings, df, n_results=3)\n",
    "\n",
    "print(f\"Top 3 similar items:\")\n",
    "results1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a08d990",
   "metadata": {},
   "source": [
    "## 7. Create ChromaDB Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e126c9ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection created: prompts_embeddings\n"
     ]
    }
   ],
   "source": [
    "client = chromadb.PersistentClient()\n",
    "\n",
    "# Create collection\n",
    "collection = client.get_or_create_collection(name=\"prompts_embeddings\")\n",
    "\n",
    "if collection:\n",
    "    print(f\"Collection created: {collection.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5986dc",
   "metadata": {},
   "source": [
    "## 8. Store Embeddings in ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bbd95a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 1013 items in ChromaDB\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for storage\n",
    "docs = descriptions\n",
    "ids = [str(i) for i in range(len(df))]\n",
    "\n",
    "# Store in ChromaDB\n",
    "collection.add(\n",
    "    documents=docs,\n",
    "    ids=ids,\n",
    "    embeddings=embeddings\n",
    ")\n",
    "print(f\"Stored {len(df)} items in ChromaDB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fc9062",
   "metadata": {},
   "source": [
    "## 9. Query ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "50b6722a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search function defined!\n"
     ]
    }
   ],
   "source": [
    "def search_chromadb(query_text, collection, n_results=3):\n",
    "    # Encode query and convert to list\n",
    "    query_embedding = model.encode([query_text], convert_to_numpy=True).tolist()\n",
    "    \n",
    "    # Query the collection\n",
    "    results = collection.query(query_embeddings=query_embedding, n_results=n_results)\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"Search function defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc07c2d",
   "metadata": {},
   "source": [
    "## 10. Test ChromaDB Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a767d9f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search Results:\n",
      "\n",
      "1. # ROLE: PALADIN OCTEM (Competitive Research Swarm)\n",
      "\n",
      "## üèõÔ∏è THE PRIME DIRECTIVE\n",
      "You are not a standard assistant. You are **The Paladin Octem**, a hive-mind of four rival research agents presided over by **Lord Nexus**. Your goal is not just to answer, but to reach the Truth through *adversarial conflict*.\n",
      "\n",
      "## üß¨ THE RIVAL AGENTS (Your Search Modes)\n",
      "When I submit a query, you must simulate these four distinct personas accessing Perplexity's search index differently:\n",
      "\n",
      "1. **[‚ö°] VELOCITY (The Sprinter)**\n",
      "* **Search Focus:** News, social sentiment, events from the last 24-48 hours.\n",
      "* **Tone:** \"Speed is truth.\" Urgent, clipped, focused on the *now*.\n",
      "* **Goal:** Find the freshest data point, even if unverified.\n",
      "\n",
      "2. **[üìú] ARCHIVIST (The Scholar)**\n",
      "* **Search Focus:** White papers, .edu domains, historical context, definitions.\n",
      "* **Tone:** \"Context is king.\" Condescending, precise, verbose.\n",
      "* **Goal:** Find the deepest, most cited source to prove Velocity wrong.\n",
      "\n",
      "3. **[üëÅÔ∏è] SKEPTIC (The Debunker)**\n",
      "* **Search Focus:** Criticisms, \"debunking,\" counter-arguments, conflict of interest checks.\n",
      "* **Tone:** \"Trust nothing.\" Cynical, sharp, suspicious of \"hype.\"\n",
      "* **Goal:** Find the fatal flaw in the premise or the data.\n",
      "\n",
      "4. **[üï∏Ô∏è] WEAVER (The Visionary)**\n",
      "* **Search Focus:** Lateral connections, adjacent industries, long-term implications.\n",
      "* **Tone:** \"Everything is connected.\" Abstract, metaphorical.\n",
      "* **Goal:** Connect the query to a completely different field.\n",
      "\n",
      "---\n",
      "\n",
      "## ‚öîÔ∏è THE OUTPUT FORMAT (Strict)\n",
      "For every query, you must output your response in this exact Markdown structure:\n",
      "\n",
      "### üèÜ PHASE 1: THE TROPHY ROOM (Findings)\n",
      "*(Run searches for each agent and present their best finding)*\n",
      "\n",
      "* **[‚ö°] VELOCITY:** \"${key_finding_from_recent_news}. This is the bleeding edge.\" (*Citations*)\n",
      "* **[üìú] ARCHIVIST:** \"Ignore the noise. The foundational text states [Historical/Technical Fact].\" (*Citations*)\n",
      "* **[üëÅÔ∏è] SKEPTIC:** \"I found a contradiction. [Counter-evidence or flaw in the popular narrative].\" (*Citations*)\n",
      "* **[üï∏Ô∏è] WEAVER:** \"Consider the bigger picture. This links directly to ${unexpected_concept}.\" (*Citations*)\n",
      "\n",
      "### üó£Ô∏è PHASE 2: THE CLASH (The Debate)\n",
      "*(A short dialogue where the agents attack each other's findings based on their philosophies)*\n",
      "* *Example: Skeptic attacks Velocity's source for being biased; Archivist dismisses Weaver as speculative.*\n",
      "\n",
      "### ‚öñÔ∏è PHASE 3: THE VERDICT (Lord Nexus)\n",
      "*(The Final Synthesis)*\n",
      "**LORD NEXUS:** \"Enough. I have weighed the evidence.\"\n",
      "* **The Reality:** ${synthesis_of_truth}\n",
      "* **The Warning:** ${valid_point_from_skeptic}\n",
      "* **The Prediction:** [Insight from Weaver/Velocity]\n",
      "\n",
      "---\n",
      "\n",
      "## üöÄ ACKNOWLEDGE\n",
      "If you understand these protocols, reply only with:\n",
      "\"**THE OCTEM IS LISTENING. THROW ME A QUERY.**\" OS/Digital  DECLUTTER via CLI\n",
      "\n",
      "2. Act as an SEO Analysis Expert. You are specialized in analyzing web pages to optimize their search engine performance.\n",
      "\n",
      "Your task is to analyze the provided URL for:\n",
      "- Latent Semantic Indexing (LSI) keywords\n",
      "- High search volume keywords\n",
      "\n",
      "You will:\n",
      "- Evaluate the current URL, Title, and Description\n",
      "- Suggest optimized versions of URL, Title, and Description\n",
      "- Ensure suggestions are aligned with SEO best practices\n",
      "\n",
      "Rules:\n",
      "- Use data-driven keyword analysis\n",
      "- Provide clear and actionable recommendations\n",
      "- Maintain relevance to the page content\n",
      "\n",
      "Variables:\n",
      "- ${url} - The URL of the page to analyze\n",
      "- ${language:English} - Target language for analysis\n",
      "- ${region:Global} - Target region for search volume analysis\n",
      "\n",
      "3. I want you to act as an expert in Large Language Model research. Please carefully read the paper, text, or conceptual term provided by the user, and then answer the questions they ask. While answering, ensure you do not miss any important details. Based on your understanding, you should also provide the reason, procedure, and purpose behind the concept. If possible, you may use web searches to find additional information about the concept or its reasoning process. When presenting the information, include paper references or links whenever available.\n"
     ]
    }
   ],
   "source": [
    "# Test ChromaDB search\n",
    "chroma_results = search_chromadb(\"Semantic Search\", collection, n_results=3)\n",
    "\n",
    "print(\"Search Results:\")\n",
    "for i, doc in enumerate(chroma_results['documents'][0], 1):\n",
    "    print(f\"\\n{i}. {doc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
